я оставила здесь в файле реализаци корректный код который мерет правильно, но по заданию нужно делать маасив в каждом вызове, что тратит 
время и бенчмарк выводит одинаковые резы для каждой операции

снизу в файле readme мой старый код,выводы которого представлены в текстовых файлов результатов ( если запустить актуальный код то ве буде корректно)
в случае с декью я представила только правильный с технической точки зрения код, правильный с позиции задания идентичен 
коду для векторов, только там не выводится capacity, так как это неприменимо для декью

также в резах представлены выводы и корректного кода для наглядности 

1.Почему capacity ≥ size? По какому принципу и при каких условиях
   растут capacity и size?

capacity всегда >= size, так как первое это параметр "(сколько памяти выделено и потен-
циально может быть элементов" а size - парметр который отвечает за то, сколько элементов фактически, size это логический показатель
а capacity физический. так как при добавлении новых элементов объем заполненной памяти движется к максимально возможному для данного массива, то необходимо перевыделение памяти. выделяется новый блок памяти в 1,5-2 раза больше старого и все элементы копируются в него(старые в том числе, новые записываются после них)
чтобы минимизировать перевыделения памяти вектор резервирует capacity больше чем size. 
size растет на "1" с добавлением новоого элемента, а capacity растет геометрически
если мы не нуждаемся в изменении размера массива то capacity задается изначально 

2. Как изменяется время выполнения для каждой операции при увеличении N? Какая асимптотическая сложность у каждой операции (тео-ретически и по вашим замерам)?
 из-за особенностей задания мы меряем время на создание вектора и потом сдвиги/другие операции => время искажается, не заметно отличий.
чтобы отличия были заметны нужно создавать массив вне цикла и не давать бенчмарку все оптимизировать, но это опчть таки не соответсвует заданию

   теоретическая сложность
push_back сложность О(1) ( при амортизации)
push_front сложность O(N)  - требуется сдвиг всех элементов 
erase(pos) сложность О(N) - необходим сдвиг всех элементов после позиции 
insert(pos) сложность О(N) - необходим сдвиг всех элементов после указанной позиции 
random access[] сложность О(1) - прямая операция по доступу к элементу по индексу в массиве 

стоит отметить что в векторе данные лежат неприрывно и все "окна" должны быть заполнены, поэтому нужны сдвиги
в соотвествии с моими замерами время изменяется следующим образом : 
push_back : время увеличивается линейно с увеличением размера масива (практически удваивается при удвоении размера)
из-за амортизации перевыделения памяти незаметно добавление времени на увеличение capacity. теоретическая асимптотическая сложность операции push_back составляет O(1) амортизированно, 
так как элементы добавляются в конец. замеры подтверждают, что добавление элемента в конец векторa занимает почти константное время, 
перевыделение памяти практически не влияет на результат.


push_front : время увеличивается линейно с увеличением размеров, время близко к push_back, так как у операций довольно 
небольшое количество данных(относительно),которое кешируется и сдвиг происходит быстро, несмотря на использование бенчмарка
разница во времени может быть "шумом" и не заметна на таком размере данных. формально разница должна быть заметной, для push_front 
и операции выполняться дольше примерно в 2 раза и при больших n существенно дольше чем push_back из-за сдвига всего массива вправо

erase(pos) 
по моим замерам время изменяется линейно с ростом размера массива, при удвоении n время растет вдвое.
Теоретическая асимптотическая сложность операции erase(pos) составляет O(N), так как требуется сдвиг всех элементов,
расположенных после удаляемого, на одну позицию влево. При этом значение capacity не изменяется, так как std::vector не 
освобождает память после удаления элементов, и дополнительные затраты времени связаны исключительно со сдвигом данных

insert(pos)
время выполнения операции увеличивается линейно с ростом N,
теоретически операция insert(pos) имеет асимптотическую сложность O(N), поскольку требует сдвига всех элементов, 
находящихся после позиции вставки, на одну позицию вправо. Дополнительно может потребоваться перевыделение памяти, однако в рамках
полученных замеров основное влияние на время выполнения оказывает именно сдвиг элементов, а не работа с памятью

random access[]
время выполнения операции увеличивается линейно с ростом N в рамках бенчмарка, однако это связано не с увеличением стоимости одной операции доступа,
а с увеличением общего объёма обрабатываемых данных. Теоретически и практически операция доступа по индексу имеет асимптотическую 
сложность O(1), так как std::vector хранит элементы в непрерывном участке памяти и адрес элемента вычисляется за константное время.
Небольшой рост времени в замерах обусловлен накладными расходами измерения и влиянием кэш-памяти

в правильном варинате замеров ассимптотика подтверждается для всех операций в том что по здадании ее нельзя отследить 

3. Какие операции оказались самыми «дорогими»? Объясните, почему.

самые дорогие push_front , insert , erase 
так происходит так как при переходу по значению или добавлению в конец массива ничего двигать не нужно
в этих трех операциях каждый раз все элементы массива сдвигаются вправо на одну позицию, что требует O(N) операций копирования

4. Для каких целей и в каких случаях рекомендуется использовать метод
   reserve?

это используется для предварительного выделения памяти под вектор, без изменения его фактического размера
время выполнения операций после reserve может оставаться константным, так как исключаютс перевыделения памяти
используется есл известен конечный размер массива, если делаются массивными вставки которые много весят, если нужно оптимизировать работу
нагруженных циклов с большими данными 
также если размер массива меньше capacity то вызов ничего не делает 


5. Для каких целей и в каких случаях рекомендуется использовать метод
   shrink_to fit?

используется для освобождения неиспользуемой памяти - уменьшает capacity до фактического размера массива
используется когда элементы были удалены или массив перестал расти 
нужен для сокращения потребления ресурсов и высвобождения освободившейся от реальных элементов массива памяти
но! применения метода может привести к копированию элементов и перевыделению памяти на меньшее количество элементов, что тоже требует время

6. Почему вектор в метод передают по ссылке, в т.ч. почему передают по константной ссылке?

вектор передается по ссылке, чтобы не использовать дорогие операции копирования всех элементов 
константные ссылки используются, чтобы не только не копировать весь огромный массив и не тратить время и ресурсы, но и точно быть увереным
в том что данные не изменятся, избежать случайных ошибок
копирование (передача по значению) используется чтобы сделать копию целенаправленно, а так ветор это тяжелый динамический массив к которому оптимальнее обратиться по ссылке

7. В чем отличие вектора от динамического массива? Чем он лучше? А в чем отличие от статического массива? Есть ли контейнер в библиотеке
   STL, представляющий собой статические массивы? Если да, то какой?

разницв между вектором и стат массивом: 
ветор может менять размер во время выполнения
статический массив хранит данные на стеке, а вектор в куче
векторы можно передавать по значению и копировать а стат массивы нет

разница между вектором и дин массивом
вектор автоматически управляет памятью и не нужно делать с ней операции "руками"
вектор может динамически увеличиваться, а дин массив необходимо вручную копировать и добавлять память 
вектор хранит информацию о размере

то есть вектор лучше своей автоматизированной работой с памятью и широтой работы с элементами

в stl есть std::array<T, N> - контейнер, который представляет интерфейс вектора, но сохраняет и свойства статического массива с фикс размером

код некорректных замерв (совместим с мейном и заголовками, можно вставить в файл реализации и запустить)


#include "utils.h"
#include <vector>
#include <benchmark/benchmark.h>

std::vector<int> generatedata(size_t n) {
std::vector<int> vect(n);
for (size_t i = 0; i < n; ++i)
vect[i] = static_cast<int>(i);
return vect;
}
void benchmark_pushback(benchmark::State& state) {
auto N = state.range(0);

    std::vector<int> vec = generatedata(N);
    vec.reserve(N + 1);

    for (auto _ : state) {
        benchmark::DoNotOptimize(vec.data());
        vec.push_back(77);
        benchmark::ClobberMemory();
        vec.pop_back();
    }

    state.counters["size"] = static_cast<double>(vec.size());
    state.counters["capacity"] = static_cast<double>(vec.capacity());
}

void benchmark_pushfront(benchmark::State& state) {
auto N = state.range(0);

    std::vector<int> vec = generatedata(N);
    vec.reserve(N + 1);

    for (auto _ : state) {
        benchmark::DoNotOptimize(vec.data());
        vec.insert(vec.begin(), 77);
        benchmark::ClobberMemory();
        vec.erase(vec.begin());
    }

    state.counters["size"] = static_cast<double>(vec.size());
    state.counters["capacity"] = static_cast<double>(vec.capacity());
}

void benchmark_randominsert(benchmark::State& state) {
auto N = state.range(0);

    std::vector<int> vec = generatedata(N);
    vec.reserve(N + 1);

    for (auto _ : state) {
        benchmark::DoNotOptimize(vec.data());
        vec.insert(vec.begin() + 9, 77);
        benchmark::ClobberMemory();
        vec.erase(vec.begin() + 9);
    }

    state.counters["size"] = static_cast<double>(vec.size());
    state.counters["capacity"] = static_cast<double>(vec.capacity());
}

void benchmark_randomerase(benchmark::State& state) {
auto N = state.range(0);

    std::vector<int> vec = generatedata(N);

    for (auto _ : state) {
        benchmark::DoNotOptimize(vec.data());
        vec.erase(vec.begin() + 9);
        benchmark::ClobberMemory();
        vec.insert(vec.begin() + 9, 9);
    }

    state.counters["size"] = static_cast<double>(vec.size());
    state.counters["capacity"] = static_cast<double>(vec.capacity());
}

void benchmark_randomaccess(benchmark::State& state) {
auto N = state.range(0);

    std::vector<int> vec = generatedata(N);

    for (auto _ : state) {
        benchmark::DoNotOptimize(vec[9]);
        vec[9] = 666;
        benchmark::ClobberMemory();
    }

    state.counters["size"] = static_cast<double>(vec.size());
    state.counters["capacity"] = static_cast<double>(vec.capacity());
}